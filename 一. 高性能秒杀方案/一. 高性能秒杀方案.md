# JAVA 性能优化，处理亿级流量架构笔记

## 一.基本框架

<img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20191107193530836.png" width="50%"/><img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/5d5181520001c34019201080.jpg" width="50%"/>

<img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20191107200051139.png" width="50%"/>



## 二. 压力测试

#### 发现并发容量问题

server端并发线程数上不去。

用性能压力测试来发现系统的瓶颈（有可能是数据库，有可能是写了什么代码拖慢了性能，也有可能是配置问题），**发现容量问题**，目前来说**50**个并发已经是瓶颈了，通常来说这是server端的configuration的问题

解决方法：

1.  **Spring-configuration-metadata.json** （ 2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar!/META-INF/spring-configuration-metadata.json）

    定位到：

    ```json
    {
    	"sourceType": "org.springframework.boot.autoconfigure.web.ServerProperties$Tomcat",
    	"defaultValue": 200, ===> defaultValue 默认200，可以增加到2000或更大
      "name": "server.tomcat.max-threads",
      "description": "Maximum number of worker threads.",
      "type": "java.lang.Integer"
    }
    ```

    所以，默认内嵌Tomact配置

    *   **server.tomcat.accept-count：等待队列长度，默认100**
    *   **server.tomcat.mac-connections：最大可连接数，默认10000**
    *   **server.tomcat.max-threads：最大工作线程数，默认200**
    *   **server.tomat.min-spare-threads：最小工作线程数，默认10**

    默认配置下，连接超过10000后出现拒绝连接情况

    默认配置下，触发的请求超过200+100后拒绝处理，所以服务端上线前一定要改配置，具体更改的方法：

    ```json
    // 在application.properties中：
    server.tomcat.accept-count = 1000
    server.tomcat.max-threads = 800 （4核8G的经验配置）
    server.tomat.min-spare-threads = 100
    ```

2.  **定制化内嵌Tomcat开发，优化keepAlive**

    **为什么要定制Tomcat？**如果没有对keepAlive进行一些限制
    
    *   会增加废连接（如果服务端单纯挂着而不进行一些操作）
    *   成为攻击对象，DDOS，恶意者对keepAlive连接无脑发送一些包
    
    **什么是keepAlive？**客户端向server发送http请求的时候，若带上keepAlive的请求头，则表明client希望和server建立keepAlive的连接**（long pull request）**，实现复用连接的目的，用以解决每次http request无状态连接完成后都要断开再连接所产生的耗时问题。
    
*   keepAliveTimeOut：多少毫秒后若客户端不响应，则断开keepalive连接
  
    *   maxKeepAliveRequests：对应的这个keepalive，多少次请求后，keepalive断开失效
    
    使用**WebServerFactoryCustomizer<ConfigurableServletWebServerFactory>**定制化内嵌Tomcat配置（SpringBoot提供的Class）
    
    ```java
    //当Spring容器内没有TomcatEmbeddedServletContainerFactory这个bean时，会吧此bean加载进spring容器中
    @Component
    public class WebServerConfiguration implements WebServerFactoryCustomizer<ConfigurableWebServerFactory> {
        @Override
        public void customize(ConfigurableWebServerFactory configurableWebServerFactory) {
            //使用对应工厂类提供给我们的接口定制化我们的tomcat connector
            ((TomcatServletWebServerFactory) configurableWebServerFactory).addConnectorCustomizers(new TomcatConnectorCustomizer() {
                @Override
                public void customize(Connector connector) {
                    Http11NioProtocol protocol = (Http11NioProtocol) connector.getProtocolHandler();
                    //定制化keepalivetimeout,设置30秒内没有请求则服务端自动断开keepalive链接
                    protocol.setKeepAliveTimeout(30000);
                    //当客户端发送超过10000个请求则自动断开keepalive链接
                    protocol.setMaxKeepAliveRequests(10000);
                }
            });
        }
    }
    ```
    
    优点：
    
    *   允许修改除了application.properties暴露出来的**properties**之外的其他的配置
    
3.  **容量问题，响应时间变长TPS上不去**

  单Web容器上限

  *   线程数量：4核cpu 8G内存单进程调度线程数**800-1000**以上后，即花费巨大的时间在CPU调度上**（content switch）**
  *   等待队列长度：队列做缓冲池用，但也不能无限长，消耗内存，出队入队也消耗cpu

  这部分有关Mysql插入或查询事务优化的问题，下面会讲。

    


## 三. 分布式扩展（接触分布式）

单机容量问题，**水平扩展**方案引入

*   nginx反向代理负载均衡
*   分布式会话管理
*   使用redis实现分布式会话存储

**⚠️Nginx 反向代理负载均衡**

**首先，你要有钱，要能买相同的多台服务器（假设买了四台，三台部署jar包一台部署nginx反向代理）**。

搭建分布式server的方式：

1.  **搭建分布服务器**

*   在阿里云买四台机器，二台用于分布server，一台用于分布Mysql，一台用于装载nginx

*   开放Mysql的远程端口，修改所有server datasource url to that ip address:

    ```json
    spring.datasource.url=jdbc:mysql://(mysql所处在机器的IP Address):3306/miaosha?...配置
    ```

*   数据库安全性：不是只要是个用户名和密码就可以连接上来，这样安全性太差了，要指定ip才能访问数据库（ip白名单）

    ```sql
    grant all priviledges on *.*(任何一个域名的用户) to root@'%'（访问root账号并且给予所有权限） identified by "root"
    
    flush privileges; (手动flush)
    ```

*   启动server1和server2的Tomcat

    

2.  **Nginx负载均衡配置**

  * 使用nginx作为web服务器
  * 使用nginx作为动静分离服务器
  * 使用nginx作为**反响代理**服务器
  
  先看一张图：
  
  ![image-20191109143618951](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20191109143618951.png)
  
  **nginx 什么时候反向代理的操作是代理到server，而什么时候又是代理到本地磁盘？**
  
  *   URL规则： 若user访问的是miaoshaserver/resources ===> 访问本地磁盘，若不是，则反向代理到server
  
3.  **部署Nginx OpenResty(OpenResty是单独下载的)，部署静态资源（resource）**

  *   **OpenResty** is a dynamic web platform based on NGINX and LuaJIT
  
  *   OpenResty 的文件结构：    
    
      *   在nginx的文件夹中，有config，html（可以把前端的东西放到这里来），sbin(nginx的命令)
      
  *   启动nginx（openresty)
  
      ```shell
      sbin/nginx -c conf/nginx.conf
      Mac下：/usr/local/Cellar/openresty/
      ```
  
      

**没钱，**可以一台机器创建多个虚拟机，具体方法是使用Vagrant 或者 Docker Machine（待研究）

https://kiwenlau.com/2016/07/03/vagrant-vm-cluster/

多个docker：https://juejin.im/post/5cdf983451882526015c3e06



**⚠️前端资源部署**

将前端文件上传至

```shell
/usr/local/Cellar/openresty/nginx/html
```



**⚠️前端资源路由**

这个我没有搞懂，配置 **nginx.conf**

* 当url访问的是resources静态资源的时候：

  ```nginx
  server {
    前面的省略...
    location /resources/ {
      alias /usr/local/openresty/nginx/html/resources/;
      index index.html index.html
    }
  }
  ```

  然后将`/usr/local/openresty/nginx/html/`下的东西全部copy到`/usr/local/openresty/nginx/html/re sources`下，输入**{ip}/resources/getotp.html**就会找到`resources`下面的**getotp.html**



⚠️**配置nginx反向代理，nginx动静分离服务器**

* location节点path特点resources：静态资源路径

* location节点其他路径：动态资源用。

* nginx做反向代理服务器

  * 设置upstream server

    ```nginx
    upstream backend_server {
      server {ip地址1} weight=1;
      server {ip地址2} weight=1;
    }
    ```

  * 设置动态请求location为proxy pass路径

    ```nginx
    location / {
      proxy_pass http://backend_server;
      proxy_set_header Host $http_hosti:$proxy_port;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    ```

    然后`sbin/nginx -s reload`重新加载配置

  * 开启**tomcat access log**验证

    ```shell
    cd //var/www/miaosha/
    mkdir tomcat
    chmod -R 777 tomcat/
    vim application.properties
    ```

    然后

    ```properties
    server.tomcat.accesslog.enabled=true
    server.tomcat.accesslog.directory=/var/www/miaosha/tomcat
    // 指定Tomcat的日志格式
    server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D 
    ```

    **%h：**remote host name，远端请求的ip地址

    **%l：**remote logical user name from identity

    **%u：**远端主机的user

    **%t：**处理时长

    **%r：**请求url

    **%s：**http请求返回状态码

    **%b：**请求response的大小

    **%D：**处理请求的时长

    然后`./deploy.sh &`和刷新页面就能看到log了



⚠️**分布式扩展后的性能压测**

直接对mysql的压力，可以分散到对两个miaosha.jar server的压力，相当于一个显卡跑游戏和两个显卡跑游戏的区别

设置nginx服务器和miaosha.jar服务器的keepAlive状态（不设置的话一直是短链接状态），修改nginx的配置

```nginx
upstream backend_server {
  server {ip地址1} weight=1;
  server {ip地址2} weight=1;
  增加：keepalive 30;（30秒keepAlive）
}

location / {
  增加：
  proxy_http_version 1.1;(因为默认是1.0没有keepAlive)
  proxy_set_header Connection "";（同样，字符段为空的话默认keepAlive）
}
```



⚠️**nginx高性能原因**

* epoll多路复用（这个再看看其他的知识吧）

  * java bio模式，阻塞进程式
  * linux select模型，变更触发轮训查找，有1024数量上限
  * epoll模型，变更出发回调直接读取，理论上无上限

* master worker进程模式

  ![image-20200330015014570](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200330015014570.png)

  ```shell
  0 12668     1   0 12:57PM ??         0:00.00 nginx: master process sbin/nginx -c config/nginx.conf
  -2 12669 12668   0 12:57PM ??         0:00.05 nginx: worker process
  501 13276  6975   0  1:52AM ttys002    0:00.00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn --exclude-dir=.idea --exclude-dir=.tox nginx
  ```

  如上，父子进程，master进程可以管理对应worker进程的内存空间，权限很大

  **这部分待补充，太多知识点**

  

* 协程（Coroutine）机制

  * 依附于线程的内存模型，切换开销小
  * 遇阻塞及归还执行权，代码同步
  * 无需加锁



⚠️**分布式会话课题引入**

**会话（session）管理**

* **基于cookie传输sessionid：java tomcat容器session实现**（缺点，移动端开发的过程会把Webview中的cookie给禁用）

  当call：{ip}:8090/item/get?id=6的时候，在Request Headers中，会有

  ```xml
  Cookie: SESSION=mdflanmfksnflf(一个字符串); JESSIONID=8932nj1n23(又一个字符串)
  ```

  **JESSIONID** 是Tomcat所返回的一个内置Cookie的标识

* **基于token传输类似sessionid：java代码session实现**

  但是这样做会有一个问题，通过nginx分配的两个miaosha.jar，分别有两个sessionId，所以每一次的请求不能保证到达同一个server，这样sessionId会不一样。

**Redis分布式会话管理机制**

前言：以上的基于Tomcat的是**不能**满足分布式的会话**管理（验证用户是否登陆的请求）**，因为单体会话session的管理方式是基于Tomcat的内存来实现的，所以我们要用Redis

* **基于cookie传输sessionid：java tomcat容器session实现迁移到redis**

  * **Redis分布式会话实现**

    1. 引入redis的jar包

    2. 配置configuration

       ```java
       @Component
       @EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
       public class RedisConfig {}
       
       对应当用户登陆的时候Session存入Redis的行为
       this.httpServletRequest.getSession().setAttribute("IS_LOGIN",true);
       this.httpServletRequest.getSession().setAttribute("LOGIN_USER",userModel);
       ```

    3. 安装redis

    4. 配置springboot对redis的依赖

       ```properties
       spring.redis.host=127.0.0.1
       spring.redis.port=6379
       spring.redis.database=10
       spring.redis.password=......
       ```

* **基于token传输类似sessionid：java代码session实现迁移到redis**

  * ```java
    //生成登录凭证token，UUID
    String uuidToken = UUID.randomUUID().toString();
    uuidToken = uuidToken.replace("-","");
    //建立token和用户登陆态之间的联系
    (RedisTemplate)redisTemplate.opsForValue().set(uuidToken, userModel);
    (RedisTemplate)redisTemplate.expire(uuidToken,1,TimeUnit.HOURS);
    //下发token
    return CommonReturnType.create(uuidToken);
    ```

    这样，当用户登陆的时候，这个**Token**就会随着**response body**返回给前端

    

## 四. 查询性能优化技术之多级缓存

**缓存设计：**

* 用快速存取设备，用内存
* 将缓存推到离用户最近的地方
* 脏缓存清理

**多级缓存**

* redis缓存
* 热点内存本地缓存
* nginx proxy cache缓存
* nginx lua 缓存

**Redis缓存**



## 附录，一些常用的Shell命令


