#  JAVA 性能优化，处理亿级流量架构笔记

## 一.基本框架

<img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20191107193530836.png" width="50%"/><img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/5d5181520001c34019201080.jpg" width="50%"/>

<img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20191107200051139.png" width="50%"/>



## 二. 压力测试

#### 发现并发容量问题

server端并发线程数上不去。

用性能压力测试来发现系统的瓶颈（有可能是数据库，有可能是写了什么代码拖慢了性能，也有可能是配置问题），**发现容量问题**，目前来说**50**个并发已经是瓶颈了，通常来说这是server端的configuration的问题

解决方法：

1.  **Spring-configuration-metadata.json** （ 2.0.5.RELEASE/spring-boot-autoconfigure-2.0.5.RELEASE.jar!/META-INF/spring-configuration-metadata.json）

    定位到：

    ```json
    {
    	"sourceType": "org.springframework.boot.autoconfigure.web.ServerProperties$Tomcat",
    	"defaultValue": 200, ===> defaultValue 默认200，可以增加到2000或更大
      "name": "server.tomcat.max-threads",
      "description": "Maximum number of worker threads.",
      "type": "java.lang.Integer"
    }
    ```

    所以，默认内嵌Tomact配置

    *   **server.tomcat.accept-count：等待队列长度，默认100**
    *   **server.tomcat.mac-connections：最大可连接数，默认10000**
    *   **server.tomcat.max-threads：最大工作线程数，默认200**
    *   **server.tomat.min-spare-threads：最小工作线程数，默认10**

    默认配置下，连接超过10000后出现拒绝连接情况

    默认配置下，触发的请求超过200+100后拒绝处理，所以服务端上线前一定要改配置，具体更改的方法：

    ```json
    // 在application.properties中：
    server.tomcat.accept-count = 1000
    server.tomcat.max-threads = 800 （4核8G的经验配置）
    server.tomat.min-spare-threads = 100
    ```

2.  **定制化内嵌Tomcat开发，优化keepAlive**

    **为什么要定制Tomcat？**如果没有对keepAlive进行一些限制
    
    *   会增加废连接（如果服务端单纯挂着而不进行一些操作）
    *   成为攻击对象，DDOS，恶意者对keepAlive连接无脑发送一些包
    
    **什么是keepAlive？**客户端向server发送http请求的时候，若带上keepAlive的请求头，则表明client希望和server建立keepAlive的连接**（long pull request）**，实现复用连接的目的，用以解决每次http request无状态连接完成后都要断开再连接所产生的耗时问题。
    
*   keepAliveTimeOut：多少毫秒后若客户端不响应，则断开keepalive连接
  
    *   maxKeepAliveRequests：对应的这个keepalive，多少次请求后，keepalive断开失效
    
    使用**WebServerFactoryCustomizer<ConfigurableServletWebServerFactory>**定制化内嵌Tomcat配置（SpringBoot提供的Class）
    
    ```java
    //当Spring容器内没有TomcatEmbeddedServletContainerFactory这个bean时，会吧此bean加载进spring容器中
    @Component
    public class WebServerConfiguration implements WebServerFactoryCustomizer<ConfigurableWebServerFactory> {
        @Override
        public void customize(ConfigurableWebServerFactory configurableWebServerFactory) {
            //使用对应工厂类提供给我们的接口定制化我们的tomcat connector
            ((TomcatServletWebServerFactory) configurableWebServerFactory).addConnectorCustomizers(new TomcatConnectorCustomizer() {
                @Override
                public void customize(Connector connector) {
                    Http11NioProtocol protocol = (Http11NioProtocol) connector.getProtocolHandler();
                    //定制化keepalivetimeout,设置30秒内没有请求则服务端自动断开keepalive链接
                    protocol.setKeepAliveTimeout(30000);
                    //当客户端发送超过10000个请求则自动断开keepalive链接
                    protocol.setMaxKeepAliveRequests(10000);
                }
            });
        }
    }
    ```
    
    优点：
    
    *   允许修改除了application.properties暴露出来的**properties**之外的其他的配置
    
3.  **容量问题，响应时间变长TPS上不去**

  单Web容器上限

  *   线程数量：4核cpu 8G内存单进程调度线程数**800-1000**以上后，即花费巨大的时间在CPU调度上**（content switch）**
  *   等待队列长度：队列做缓冲池用，但也不能无限长，消耗内存，出队入队也消耗cpu

  这部分有关Mysql插入或查询事务优化的问题，下面会讲。

    


## 三. 分布式扩展（接触分布式）

单机容量问题，**水平扩展**方案引入

*   nginx反向代理负载均衡
*   分布式会话管理
*   使用redis实现分布式会话存储

**⚠️Nginx 反向代理负载均衡**

**首先，你要有钱，要能买相同的多台服务器（假设买了四台，三台部署jar包一台部署nginx反向代理）**。

搭建分布式server的方式：

1.  **搭建分布服务器**

*   在阿里云买四台机器，二台用于分布server，一台用于分布Mysql，一台用于装载nginx

*   开放Mysql的远程端口，修改所有server datasource url to that ip address:

    ```json
    spring.datasource.url=jdbc:mysql://(mysql所处在机器的IP Address):3306/miaosha?...配置
    ```

*   数据库安全性：不是只要是个用户名和密码就可以连接上来，这样安全性太差了，要指定ip才能访问数据库（ip白名单）

    ```sql
    grant all priviledges on *.*(任何一个域名的用户) to root@'%'（访问root账号并且给予所有权限） identified by "root"
    
    flush privileges; (手动flush)
    ```

*   启动server1和server2的Tomcat

    

2.  **Nginx负载均衡配置**

  * 使用nginx作为web服务器
  * 使用nginx作为动静分离服务器
  * 使用nginx作为**反响代理**服务器
  
  先看一张图：
  
  ![image-20191109143618951](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20191109143618951.png)
  
  **nginx 什么时候反向代理的操作是代理到server，而什么时候又是代理到本地磁盘？**
  
  *   URL规则： 若user访问的是miaoshaserver/resources ===> 访问本地磁盘，若不是，则反向代理到server
  
3.  **部署Nginx OpenResty(OpenResty是单独下载的)，部署静态资源（resource）**

  *   **OpenResty** is a dynamic web platform based on NGINX and LuaJIT
  
  *   OpenResty 的文件结构：    
    
      *   在nginx的文件夹中，有config，html（可以把前端的东西放到这里来），sbin(nginx的命令)
      
  *   启动nginx（openresty)
  
      ```shell
      sbin/nginx -c conf/nginx.conf
      Mac下：/usr/local/Cellar/openresty/
      ```
  
      

**没钱，**可以一台机器创建多个虚拟机，具体方法是使用Vagrant 或者 Docker Machine（待研究）

https://kiwenlau.com/2016/07/03/vagrant-vm-cluster/

多个docker：https://juejin.im/post/5cdf983451882526015c3e06



**⚠️前端资源部署**

将前端文件上传至

```shell
/usr/local/Cellar/openresty/nginx/html
```



**⚠️前端资源路由**

这个我没有搞懂，配置 **nginx.conf**

* 当url访问的是resources静态资源的时候：

  ```nginx
  server {
    前面的省略...
    location /resources/ {
      alias /usr/local/openresty/nginx/html/resources/;
      index index.html index.html
    }
  }
  ```

  然后将`/usr/local/openresty/nginx/html/`下的东西全部copy到`/usr/local/openresty/nginx/html/re sources`下，输入**{ip}/resources/getotp.html**就会找到`resources`下面的**getotp.html**



⚠️**配置nginx反向代理，nginx动静分离服务器**

* location节点path特点resources：静态资源路径

* location节点其他路径：动态资源用。

* nginx做反向代理服务器

  * 设置upstream server

    ```nginx
    upstream backend_server {
      server {ip地址1} weight=1;
      server {ip地址2} weight=1;
    }
    ```

  * 设置动态请求location为proxy pass路径

    ```nginx
    location / {
      proxy_pass http://backend_server;
      proxy_set_header Host $http_hosti:$proxy_port;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    ```

    然后`sbin/nginx -s reload`重新加载配置

  * 开启**tomcat access log**验证

    ```shell
    cd //var/www/miaosha/
    mkdir tomcat
    chmod -R 777 tomcat/
    vim application.properties
    ```

    然后

    ```properties
    server.tomcat.accesslog.enabled=true
    server.tomcat.accesslog.directory=/var/www/miaosha/tomcat
    // 指定Tomcat的日志格式
    server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D 
    ```

    **%h：**remote host name，远端请求的ip地址

    **%l：**remote logical user name from identity

    **%u：**远端主机的user

    **%t：**处理时长

    **%r：**请求url

    **%s：**http请求返回状态码

    **%b：**请求response的大小

    **%D：**处理请求的时长

    然后`./deploy.sh &`和刷新页面就能看到log了



⚠️**分布式扩展后的性能压测**

直接对mysql的压力，可以分散到对两个miaosha.jar server的压力，相当于一个显卡跑游戏和两个显卡跑游戏的区别

设置nginx服务器和miaosha.jar服务器的keepAlive状态（不设置的话一直是短链接状态），修改nginx的配置

```nginx
upstream backend_server {
  server {ip地址1} weight=1;
  server {ip地址2} weight=1;
  增加：keepalive 30;（30秒keepAlive）
}

location / {
  增加：
  proxy_http_version 1.1;(因为默认是1.0没有keepAlive)
  proxy_set_header Connection "";（同样，字符段为空的话默认keepAlive）
}
```



⚠️**nginx高性能原因**

* epoll多路复用（这个再看看其他的知识吧）

  * java bio模式，阻塞进程式
  * linux select模型，变更触发轮训查找，有1024数量上限
  * epoll模型，变更出发回调直接读取，理论上无上限

* master worker进程模式

  ![image-20200330015014570](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200330015014570.png)

  ```shell
  0 12668     1   0 12:57PM ??         0:00.00 nginx: master process sbin/nginx -c config/nginx.conf
  -2 12669 12668   0 12:57PM ??         0:00.05 nginx: worker process
  501 13276  6975   0  1:52AM ttys002    0:00.00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn --exclude-dir=.idea --exclude-dir=.tox nginx
  ```

  如上，父子进程，master进程可以管理对应worker进程的内存空间，权限很大

  **这部分待补充，太多知识点**

  

* 协程（Coroutine）机制

  * 依附于线程的内存模型，切换开销小
  * 遇阻塞及归还执行权，代码同步
  * 无需加锁



⚠️**分布式会话课题引入**

**会话（session）管理**

* **基于cookie传输sessionid：java tomcat容器session实现**（缺点，移动端开发的过程会把Webview中的cookie给禁用）

  当call：{ip}:8090/item/get?id=6的时候，在Request Headers中，会有

  ```xml
  Cookie: SESSION=mdflanmfksnflf(一个字符串); JESSIONID=8932nj1n23(又一个字符串)
  ```

  **JESSIONID** 是Tomcat所返回的一个内置Cookie的标识

* **基于token传输类似sessionid：java代码session实现**

  但是这样做会有一个问题，通过nginx分配的两个miaosha.jar，分别有两个sessionId，所以每一次的请求不能保证到达同一个server，这样sessionId会不一样。

**Redis分布式会话管理机制**

前言：以上的基于Tomcat的是**不能**满足分布式的会话**管理（验证用户是否登陆的请求）**，因为单体会话session的管理方式是基于Tomcat的内存来实现的，所以我们要用Redis

* **基于cookie传输sessionid：java tomcat容器session实现迁移到redis**

  * **Redis分布式会话实现**

    1. 引入redis的jar包

    2. 配置configuration

       ```java
       @Component
       @EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
       public class RedisConfig {}
       
       对应当用户登陆的时候Session存入Redis的行为
       this.httpServletRequest.getSession().setAttribute("IS_LOGIN",true);
       this.httpServletRequest.getSession().setAttribute("LOGIN_USER",userModel);
       ```

    3. 安装redis

    4. 配置springboot对redis的依赖

       ```properties
       spring.redis.host=127.0.0.1
       spring.redis.port=6379
       spring.redis.database=10
       spring.redis.password=......
       ```

* **基于token传输类似sessionid：java代码session实现迁移到redis**

  * ```java
    //生成登录凭证token，UUID
    String uuidToken = UUID.randomUUID().toString();
    uuidToken = uuidToken.replace("-","");
    //建立token和用户登陆态之间的联系
    (RedisTemplate)redisTemplate.opsForValue().set(uuidToken, userModel);
    (RedisTemplate)redisTemplate.expire(uuidToken,1,TimeUnit.HOURS);
    //下发token
    return CommonReturnType.create(uuidToken);
    ```

    这样，当用户登陆的时候，这个**Token**就会随着**response body**返回给前端

    

## 四. 查询性能优化技术之多级缓存

**⚠️缓存设计：**

* 用快速存取设备，用内存
* 将缓存推到离用户最近的地方
* 脏缓存清理

**⚠️多级缓存**

* redis缓存
* 热点内存本地缓存
* nginx proxy cache缓存
* nginx lua 缓存

**⚠️Redis缓存**

先来看一下如果Redis加进来，整体框架会变成怎样：

![image-20200405185341757](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200405185341757.png)

* **单机版**

  所有的存储操作都在这台对应的redis上面，和mysql是运行在一个机器的

  弊端：

  1. 如果这个故障了，那么所有的业务操作都会block，都会受到影响
  2. 单机版的redis有容量的上限

* **sentianl**哨兵版（长连接版）

  <img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/5d6cccac0001840c19201080.jpeg" width="90%" />

  * 集群**cluster**模式

    <img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/5d6ccef9000185db19201080.jpeg" width="50%"/>

  上代码：（商品详情动态内容的）

  ```java
  ItemController.java （ItemController要实现Serializable）
  @Autowired
  private RedisTemplate redisTemplate;
  
  //商品详情页浏览
  @RequestMapping(value = "/get",method = {RequestMethod.GET})
  @ResponseBody
  public CommonReturnType getItem(@RequestParam(name = "id")Integer id){
  	ItemModel itemModel = null;
  	//先取本地缓存
  	itemModel = (ItemModel) cacheService.getFromCommonCache("item_"+id);
  	if(itemModel == null){
  		//根据商品的id到redis内获取
  		itemModel = (ItemModel) redisTemplate.opsForValue().get("item_"+id);
  		//若redis内不存在对应的itemModel,则访问下游service
      if(itemModel == null){
      	itemModel = itemService.getItemById(id);
        //设置itemModel到redis内
        redisTemplate.opsForValue().set("item_"+id,itemModel);
        redisTemplate.expire("item_"+id,10, TimeUnit.MINUTES);
      }
      //填充本地缓存
      cacheService.setCommonCache("item_"+id,itemModel);
  	}
  	ItemVO itemVO = convertVOFromModel(itemModel);
  	return CommonReturnType.create(itemVO);
  }
  ```

  以上代码的**作用**：当访问具体一个item的时候（**...url/items/get?id=6**）,如果redis没有这个key（item id），则加入这个item id序列化后的值和对应的item as value到redis（一个string值和一个json值），以及加上一个过期时间。这样，在这个过期时间之内，我们不用反复的去访问mysql数据库。（**从本地缓存或者redis key对应的序列化java value中拿**）

  但是以上代码的**问题**：序列化后的key和value，**太乱了（乱码）**，不利于以后调试

  **解决办法**：重新改造**Redis Template**

  ```java
  @Component
  @EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
  public class RedisConfig {
  	@Bean
  	public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){
  		RedisTemplate redisTemplate = new RedisTemplate();
      redisTemplate.setConnectionFactory(redisConnectionFactory);
  		//首先解决key的序列化方式
      StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
      redisTemplate.setKeySerializer(stringRedisSerializer);
  		//解决value的序列化方式
      Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
      //扩展对应的JacksonToJson
  		ObjectMapper objectMapper =  new ObjectMapper();
      SimpleModule simpleModule = new SimpleModule();
      simpleModule.addSerializer(DateTime.class,new JodaDateTimeJsonSerializer());
      simpleModule.addDeserializer(DateTime.class,new JodaDateTimeJsonDeserializer());
      //1.enableDefaultTyping的好处是，序列化的value可以包含类class的信息
  		objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
  		//2.objectMapper注册一个dataModal
      objectMapper.registerModule(simpleModule);
  		jackson2JsonRedisSerializer.setObjectMapper(objectMapper);
  		redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);
  		return redisTemplate;
    }
  }
  ```

  以及对DateTime的**序列化**以及去**序列化**

  ```java
  public class JodaDateTimeJsonSerializer extends JsonSerializer<DateTime> {
  	@Override
    public void serialize(DateTime dateTime, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
    	jsonGenerator.writeString(dateTime.toString("yyyy-MM-dd HH:mm:ss"));
  	}
  }
  
  public class JodaDateTimeJsonDeserializer extends JsonDeserializer<DateTime> {
  	@Override
    public DateTime deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JsonProcessingException {
    	String dateString =jsonParser.readValueAs(String.class);
      DateTimeFormatter formatter = DateTimeFormat.forPattern("yyyy-MM-dd HH:mm:ss");
  		return DateTime.parse(dateString,formatter);
  	}
  }
  ```

  这样放进redis的序列化数据就清爽多了

  

**⚠️本地热点缓存**

上一点，所有对Redis的存或者取都需要经过网络的IO到达Redis的server，并且更新Redis的状态，所以如果要更高的性能，本地热点缓存（第二级），见以下特点

* 热点数据（Java虚拟机JVM的缓存）
* 脏读不敏感：本地热点缓存在分布式的环境下，每台机器都有缓存的备份数据，而且清除每台机器的相同数据不容易
* 内存可控：本地热点缓存生命周期短

**Guava cache**

* 可控制的大小和超时时间
* 可配置的LRU （最少访问先被淘汰）策略
* 线程安全

上代码（封装Cache Server的组件来完成Guava的存和取）：

```java
@Service
public class CacheServiceImpl implements CacheService {
	private Cache<String,Object> commonCache = null;
  
	@PostConstruct //Bean加载的时候优先执行init的方法
  public void init(){
  	commonCache = CacheBuilder.newBuilder()
    //设置缓存容器的初始容量为10
    .initialCapacity(10)
    //设置缓存中最大可以存储100个KEY,超过100个之后会按照LRU的策略移除缓存项
    .maximumSize(100)
    //设置写缓存后多少秒过期
    .expireAfterWrite(60, TimeUnit.SECONDS).build();
	}
	@Override
  public void setCommonCache(String key, Object value) {
  	commonCache.put(key,value);
	}
  @Override
  public Object getFromCommonCache(String key) {
  	return commonCache.getIfPresent(key);
	}
}

然后在ItemController中：
@Autowired
private CacheService cacheService;
//商品详情页浏览
@RequestMapping(value = "/get",method = {RequestMethod.GET})
@ResponseBody
public CommonReturnType getItem(@RequestParam(name = "id")Integer id){
	ItemModel itemModel = null;
	//先取本地缓存
  itemModel = (ItemModel) cacheService.getFromCommonCache("item_"+id);
	if(itemModel == null){
  	//根据商品的id到redis内获取
    itemModel = (ItemModel) redisTemplate.opsForValue().get("item_"+id);
		//若redis内不存在对应的itemModel,则访问下游service
    if(itemModel == null){
    	itemModel = itemService.getItemById(id);
      //设置itemModel到redis内
      redisTemplate.opsForValue().set("item_"+id,itemModel);
      redisTemplate.expire("item_"+id,10, TimeUnit.MINUTES);
    }
    //填充本地缓存
    cacheService.setCommonCache("item_"+id,itemModel);
  }
  ItemVO itemVO = convertVOFromModel(itemModel);
  return CommonReturnType.create(itemVO);
}
```

**⚠️NGINX PROXY CACHE缓存实现**

就是缓存直接在Nginx上面做，绕过miaosha.jar

* Nginx 反向代理前置
* 依靠文件系统索引级的文件
*  依靠内存缓存文件地址

具体实现：**nginx.conf**

```nginx
#申明一个cache缓存节点的内容
proxy_cache_path /usr/local/openresty/nginx/tmp_cahce levels=1:2 keys_zone=tmp_cahce:100m inactive=7d max_size=10g;

location / {
  ...
  proxy_cache tmp_cahce;
  proxy_cache_key $uri;
  proxy_cache_valid 200 206 304 302 7d; ===> 只有在以下的状态码才缓存
}
```

* 地址
* levels=1:2 对应的一个文件的级别，在tmp_cache目录下，可以直接以get_item=6的id作为文件名，也可以做二级目录，将对应的url做一次hash，取最后一位做一个文件目录的索引，然后再取一位做第二级目录的索引，这样所有的文件可以分散到多个目录中，减少只有一级目录的一个寻址消耗（当所有文件都在一级目录下查找起来其实很费劲的）
* keys_zone=temp_cache 在nginx中，开了一个100m的内存空间来存储这个叫tmp_cache的keys_zone中的所有的keys
* inactive 文件可以存储7天
* max_size 最多存10G

**但是**，以上这么做会有一个问题，tps性能会提升，但是平均耗时会增加，虽然现在直接读的是nginx中的东西，没有访问miaosha.jar，但是读的其实是nginx本地磁盘的内容，而不是nginx内存中的内容，读SATA肯定是比读RAM要慢的。

**解决办法：**抛弃上面写的东西，**nginx lua原理**（新的开发缓存的方式）

协程的方式：优点是不用管异步的方式，可以以同步的方式来写代码

* lua协程机制

* nginx协程

  * nginx的每一个Worker进程都是在epoll或kqueue这种时间模型之上，封装成协程
    * 当某一个socket的据点接收到http request的操作的时候，这个epoll对应的socket就会被唤醒，唤醒之后就会获得socket对应的一个http的request的请求，这个时候nginx就会new出一个协程，这个协程就会处理http请求的完整生命周期，也就是处理url location的路由，access control的健全，string的反向代理等等的操作（具体自己百度）。在这些操作内，如果没有遇到IO阻塞的情况，那么这个协程处理完成后就会返回http response给epoll模型作为socket的wirte输出。
    * 假如遇到block的操作，如nginx反向代理到一个服务器，然后等待服务器的返回操作。这时协程会主动放弃执行权限，然后主动将跟后端反向代理服务器的一个socket的连接注册到epoll事件里，等待这个epoll事件被反向唤醒。
    * 一旦被唤醒，nginx的worker又回重新new一个协程出来做之后的事情
    * 因此，它的每一个操作都不会block对应的一个worker进程对应的操作，都是依赖于epoll自身的操作，看上去就是几个协程串行在一起。
  * 每一个请求都有一个协程进行处理
  * 即使ngx_lua需要运行Lua，相对C有一定的开销，但依旧能保证高并发能力

* nginx协程机制

  * nginx每个工作进程创建一个lua虚拟机
  * 工作进程内的所有协程共享同一个vm
  * 每个外部请求由一个lua协程处理，之间数据隔离
  * lua代码调用io等异步接口时，协程被挂起，上下文数据
  * 自动保存，不阻塞工作进程
  * io异步操作完成后还原协程上下文，代码继续执行

* nginx lua插载点

  ![image-20200407213102370](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200407213102370.png)

  * init_by_lua：系统启动时调用
  * init_worker_by_lua：worker进程启动时调用
  * set_by_lua：nginx变量用复杂lua return
  * rewrite_by_lua：权限验证阶段
  * content_by_lua：内容输出节点

  具体的实现（实战）：

  1. ```shell
     cd /usr/local/Cellar/openresty
     mkdir lua --> cd lua/
     vim init.lua ---> 然后编写点东西
     ```

  2. 修改nginx.conf

     ```nginx
     server {
       ...
       location /staticitem/get{
         default_type "text/html"
         content_by_lua_file ../lua/staticitem.lua
       }
     }
     ```

  3. ```lua
     staticite.lua
     ngx.say("") 
     ```

* OpenResty

  * OpenResty由Nginx核心加很多第三方模块组成，默认继集成了Lua开发环境，使得Nginx可以作为一个Web Server使用。
  * 借助于nginx的事件驱动模型和非阻塞IO，可以实现高性能的Web应用程序
  * OpenResty提供了大量组件如Mysql、Redis、Memcached等等，使在Nginx上开发Web应用更方便更简单

  实战：

  * shared dic：共享内存字典，所有worker进程进程可见，LRU淘汰

    **nginx.conf**

    ```nginx
    lua_shared_dict my_cache 128m;
    server {
      ...
      location /luaitem/get{
        default_type "application/json";
        content_by_lua_file ../lua/itemshared.lua;
      }
    }
    ```

    **itemsharedic.lua**

    ```lua
    function get_from_cache(key)
      local cache_ngx = ngx.shared.my_cache
      local value = cache_ngx:get(key)
      return value
    end
    
    function set_to_cahce(key, value, exptime)
      if not exptime then
        exptime = 0
      end
      local cache_ngx = ngx.shared.my_cache
      local succ,err,forcible = cache_ngx:set(key,value,exptime)
      return succ
    end
    
    local args = ngx.req.get_uri_args()
    local id = args["id"]
    local item_model = get_from_cache("item_"..id)
    if item_model == nil then
      local resp = ngx.location.capture("/item/get?id="..id)
      item_model = resp.body
      set_to_cache("item_"..id.item_model,1*60)
    end
    ngx.say(item_model)
    ```

  * Openresty Redis支持

    为什么要Redis支持？因为要兼顾更新机制和容量问题，读redis的好处，见图

    <img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/5d6e21a4000140a019201080.jpeg" width="80%"/>

    实现：

    1. 打开openresty对redis访问的支持和脚本编写

       **itemredis.lua**

       ```lua
       local args = ngx.req.get_uri_args()
       local id = args["id"]
       local redis = require "rest.redis"
       local cache = redis:new()
       local ok,err = cache:connect("部署redis的服务器ip","6379")
       local item_model = cache:get("item_"..id)
       if item_model == ngx.null or item_model == nil then
         local resp = ngx.location.capture("/item/get?id="..id)
         item_model = resp.body
       end
       ngx.say(item_model)
       ```

    2. **Nginx.conf**

       ```nginx
       location /luaitem/get{
         content_by_lua_file ../lua/itemredis.lua ---> 修改文件
       }
       ```

       

协程机制：

* 依附于线程的内存模型，切换开销小
* 遇到阻塞及归还执行权，代码同步
* 无需加锁



## 五. 查询性能优化技术之页面静态化【动态请求加静态页面一同静态化】

**⚠️引入静态资源CDN：对H5（static），miaoshaserver/resources的优化**

* DNS用CNAME解析到源站	
* 回源缓存设置
* 强推失效

<img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/5d75de4d0001b7c219201080.jpeg" width="50%"/><img src="/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200411015539297.png" width="50%"/>

**回源缓存的一些设置**

cache control响应头（在Response Headers），作用：服务端用来告诉客户端，这个HTTP Response，客户端可不可以缓存，和以什么样的策略去缓存，以下为cache-control后面接的值

* private：客户端可以缓存
* public：客户端和代理服务器都可以缓存
* max-age=xxx：缓存的内容将在xxx秒后失效
* no-cahe: 强制向服务端再验证一次
* no-store：不缓存请求的任何返回内容

见图：

![image-20200411021339518](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200411021339518.png)

有效性判断：

* **ETag**：资源唯一标识，请求资源的内容做一个MD5等等Hash化生成一个ETag的唯一标识，在第一次返回这个内容当中，加上这个ETag的唯一标识，一起返回给浏览器，浏览器会存储下来，下一次的客户端请求就连同这个ETag一起发回给服务器做验证，服务端会把这个ETag和本地的ETag内容作一个比较，若比较是一致的，返回**Http Status** **304（not modify）**，表明这个服务是有效的，直接使用缓存的即可。
* **If-None-Match**：客户端发送的匹配ETag标识符
* **Last-modified**：资源最后被修改的时间
* **If-Modified-Since**：客户端发送的匹配资源最后修改时间的标识符

![image-20200411022857328](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200411022857328.png)

浏览器三种刷新方式

* 回车刷新或a链接：看cache-control对应的max-age是否仍然有效，有效则直接from cache，若cahce-control中为no-cache，则进入缓存协商逻辑
* F5刷新：去掉cache-control中的max-age或直接设置max-age为0，然后进入缓存协商逻辑
* 强制刷新：去掉cache-control和协商头，强制刷新
* 协商机制，比较Last-modified和ETag到服务端，若服务端判断没变化则304不返回数据，否则200返回数据

**⚠️CDN自定义缓存策略**

* 可自定义目录过期时间
* 可自定义后缀名过期时间
* 可自定义对应权重
* 可通过界面或qpi强制cdn对应目录刷新（非保成功）

![image-20200411024857632](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200411024857632.png)

**⚠️静态资源部署策略**

* css，js，img等元素使用带版本号部署，例如a.js?v=1.0，缺点：不便利，且维护困难
* css，js，img等元素使用带摘要部署，例如a.js?v=45edw，缺点：存在先部署html还是先部署资源的覆盖问题
*  css，js，img等元素使用摘要做文件名部署，例如45edw.js，新老版本并存且可回滚，资源部署完成后再部署html
* 对应静态资源保持生命周期内不会变，max-age可设置的很长，无视失效更新周期
* html文件设置no-cache或较短max age，以便于更新
* html文件仍然设置较长的max age，依靠动态的获取版本号请求发送到后段，异步下载最新的版本号的html后展示渲染再前端
* 动态请求也可以静态化成json资源推到cdn上
* 依靠异步请求获取后段节点对应资源状态做紧急下架处理
* 可通过跑批紧急推送cdn内容以使其下架等操作

**⚠️全页面静态化**

* html，css，js静态资源cdn化
* js ajax动态请求cdn化
* 全页面静态化 

定义：在服务端完成html，css，甚至js的load渲染成纯html文件后直接以静态资源的方式部署到cdn上

**phantomjs**应用

* 无头浏览器，可以借助其模拟webkit js的执行
* 修改需要全页面静态化的实现，采用initView和hasInit方式防止多次初始化
* 编写对应轮讯生成内容方式
* 将全静态化页面生成后推送到CDN

代码实现：

```js
var page = require("webpage").create();
var fs = require("fs");
page.open("http://miaoshaserver/resources/getitem.html?id=6", function(status){

})
```



## 六. 交易性能优化技术之缓存库存【用缓存解决交易问题】

交易流程的优化前的**问题**

先用Jmeter压测进行交易时的**miaosha.jar**的压力和用Jmeter压测进行交易时的**数据库**的压力

```json 
{
  url: '/order/createorder?token=3e......',
	method: 'POST',
  Body：{itemId:6, amount: 1, promoId: 1}
}
```

可以发现，miaosha.jar所在应用服务器的耗用资源会比较多，但是没关系，因为这种服务器可以水平扩展。

数据库所在的服务器，虽然CPU的占用资源不高，但是压测平均耗时（数据IO操作）已经超过2秒了。

可能存在的问题：看代码

```java
@Override
@Transactional
public OrderModel createOrder(Integer userId, Integer itemId, Integer promoId, Integer amount) throws BusinessException {
	//1.校验下单状态,(1)下单的商品是否存在，(2)用户是否合法，(3)购买数量是否正确
  ItemModel itemModel = itemService.getItemById(itemId);
  if(itemModel == null){
    throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"商品信息不存在");
	}
  UserModel userModel = userService.getUserById(userId);
  if(userModel == null){
  	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"用户信息不存在");
  }
  if(amount <= 0 || amount > 99){
  	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"数量信息不正确");
  }
	//1.1校验活动信息
  if(promoId != null){
  	//(1)校验对应活动是否存在这个适用商品
    if(promoId.intValue() != itemModel.getPromoModel().getId()){
    	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"活动信息不正确");
      //(2)校验活动是否正在进行中
    }else if(itemModel.getPromoModel().getStatus().intValue() != 2) {
    	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"活动信息还未开始");
    }
  }
  //完成以上5条校验之后，其实已经向数据库发送了5条SQL
  //2.落单减库存
  boolean result = itemService.decreaseStock(itemId,amount);
  if(!result){
  	throw new BusinessException(EmBusinessError.STOCK_NOT_ENOUGH);
  }
  //3.订单入库
  OrderModel orderModel = new OrderModel();
  orderModel.setUserId(userId);
  orderModel.setItemId(itemId);
  orderModel.setAmount(amount);
  if(promoId != null){
  	orderModel.setItemPrice(itemModel.getPromoModel().getPromoItemPrice());
  }else{
  	orderModel.setItemPrice(itemModel.getPrice());
  }
  orderModel.setPromoId(promoId);
  orderModel.setOrderPrice(orderModel.getItemPrice().multiply(new BigDecimal(amount)));
	//3.1生成交易流水号,订单号
  orderModel.setId(generateOrderNo());
	OrderDO orderDO = convertFromOrderModel(orderModel);
  orderDOMapper.insertSelective(orderDO);
	//3.2加上商品的销量
  itemService.increaseSales(itemId,amount);
  //4.返回前端
  return orderModel;
}
```

根据以上的代码，目前完成这个function至少对数据库完成了6次的IO操作

![image-20200411151446721](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200411151446721.png)

**⚠️交易验证优化**

* 用户风控策略优化：策略**缓存**模型化
* 活动校验策略优化：引入活动发布流程，模型**缓存**化（预热），紧急下线能力

对以上的代码优化

```java
//1. 在ItemService中另外开一个Service，通过缓存获取用户validate
ItemModel getItemByIdInCache(Integer id) {
	ItemModel itemModel = (ItemModel)redisTemplate.opsForValue().get("item_validate_"+id);
  if(itemModel==null){
		itemModel = this.getItemById(id);
    // 若要是紧急下线活动直接在这里打上break
    redisTemplate.opsForValue().set("item_validate_"+id,itemModel);
    redisTemplate.expire("item_validate_"+id,10,TimeUnit.MINUTES);
  }
  return itemModel;
};

//2. 同样，在UserService中，另开一个接口，通过缓存获取用户对象
UserModel getUserByIdInCache(Integer id) {
  UserModel userModel = redisTemplate.opsForValue).get("user_validate_"+id);
  if(userModel == null){
    userModel = this.getUserById(id);
    redisTemplate.opsForValue().set("user_validate_"+id,userModel);
    redisTemplate.expire("user_validate_"+id,10,TimeUnit.MINUTES);
  }
  return userModel;
}


//2. 回到OrderService，就是上面那个代码，改进
public OrderModel createOrder(Integer userId, Integer itemId, Integer promoId, Integer amount, String stockLogId) throws BusinessException {
	//1.校验下单状态,下单的商品是否存在，用户是否合法，购买数量是否正确
  (改进)ItemModel itemModel = itemService.getItemByIdInCache(itemId); --> 减少对MYSQL的依赖
  if (itemModel == null) {
  	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "商品信息不存在");
	}
  (改进)UserModel userModel = userService.getUserByIdInCache(userId);
  if (userModel == null) {
  	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "用户信息不存在");
	}
  if (amount <= 0 || amount > 99) {
  	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "数量信息不正确");
	}
	//1.1校验活动信息(内存操作)
  if (promoId != null) {
  	//(1)校验对应活动是否存在这个适用商品
	  if (promoId.intValue() != itemModel.getPromoModel().getId()) {
      throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "活动信息不正确");
      //(2)校验活动是否正在进行中
    } else if (itemModel.getPromoModel().getStatus().intValue() != 2) {
    	throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "活动信息还未开始");
    }
  }
  //2.落单减库存
  boolean result = itemService.decreaseStock(itemId, amount);
  if (!result) {
    throw new BusinessException(EmBusinessError.STOCK_NOT_ENOUGH);
  }
  //3.订单入库
  OrderModel orderModel = new OrderModel();
  orderModel.setUserId(userId);
  orderModel.setItemId(itemId);
  orderModel.setAmount(amount);
  if (promoId != null) {
    orderModel.setItemPrice(itemModel.getPromoModel().getPromoItemPrice());
  } else {
  	orderModel.setItemPrice(itemModel.getPrice());
  }
  orderModel.setPromoId(promoId);
  orderModel.setOrderPrice(orderModel.getItemPrice().multiply(new BigDecimal(amount)));
	//生成交易流水号,订单号
  orderModel.setId(generateOrderNo());
  OrderDO orderDO = convertFromOrderModel(orderModel);
  orderDOMapper.insertSelective(orderDO);
	//加上商品的销量
  itemService.increaseSales(itemId, amount);
  //设置库存流水状态为成功
  StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
  if (stockLogDO == null) {
    throw new BusinessException(EmBusinessError.UNKNOWN_ERROR);
  }
  stockLogDO.setStatus(2);
  stockLogDOMapper.updateByPrimaryKeySelective(stockLogDO);
//        TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() {
//                @Override
//                public void afterCommit(){
//                    //异步更新库存
//                    boolean mqResult = itemService.asyncDecreaseStock(itemId,amount);
////                    if(!mqResult){
////                        itemService.increaseStock(itemId,amount);
////                        throw new BusinessException(EmBusinessError.MQ_SEND_FAIL);
////                    }
//                }
//
//        });
  //4.返回前端
  return orderModel;
}
```

**⚠️库存行(hang)锁优化**

先来看下Mapper中的SQL

```xml
<update id="decreaseStock">
  update item_stock
  set stock = stock - #{amount}
  where item_id = #{itemId} and stock >= #{amount}
</update>
```

此，数据库会在#{itemId}对应的row处加上一个行锁，前提是对应的#{itemId}必须是有索引的。

**创建索引**

```sql
alter table item_stock add unique index item_id_index(item_id)
```

优化：

* 扣减库存缓存化：扣减库存的操作做进Redis

  1. 活动发布同步库存进缓存

     **PromoService.java**

     ```java
     // 活动发布
     publishPromo(Integer promoId){
       //通过活动id获取活动
       PromoDO promoDO = promoDOMapper.selectByPrimaryKey(promoId);
       if(promoDO.getItemId() == null || promoDO.getItemId().intValue() == 0){
         return;
       }
     	ItemModel itemModel = itemService.getItemById(promoDO.getItemId());
       //这里有个问题，从MySql数据库拿出这个商品到存到Redis的这个过程中，这个商品是有可能被售卖的，解决办法，活动开始时，做个上架商品的动作，活动还没开始，则做下架状态，这样在业务层面解决这个问题
       //将库存同步到redis内
      redisTemplate.opsForValue().set('promo_item_stock_'+itemModel.getId(),itemModel.getStock());
     }
     ```

     **ItemController.java** 发布这个商品

     ```java
     CommonReturnType publishPromo(@RequestParam(name="id") Integer id){
       promoService.publishPromo(id);
       return CommonReturnType.create(null);
     }
     ```

  2. 下单交易减缓存库存

     **ItemSerivce.java**

     ```java
     public boolean decreaseStock(Integer itemId, Integer amount) throws BusinessException {
       long result = redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue()*-1);
       if(result >0){
         //更新库存成功
         return true;
       }else if(result == 0){
         //打上库存已售罄的标识
     		redisTemplate.opsForValue().set("promo_item_stock_invalid_"+itemId,"true");
         //更新库存成功
         return true;
       }else{
         //更新库存失败
         increaseStock(itemId,amount);
         return false;
       }
     }
     ```

     以上的问题：

     1. 数据库记录不一致，解决方法如下：**异步**

* 异步同步数据库：

  1. 活动发布同步库存进缓存

  2. 下单交易减缓存库存

  3. **异步消息**扣减数据库内库存

     异步消息队列**rocketmq**

     * 高性能，高并发，分布式消息中间件
     * 典型应用场景：分布式事务，异步解耦

     概念模型：

     ![image-20200411220730724](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/image-20200411220730724.png)

     

* 库存数据库最终一致性保证

  ![image-20200412142420216](/Users/hptg/Documents/Project/Java/High_Concurrency_Solution/Resource/10.png)

  **RocketMQ具体的使用方式：**

  根据官网安装，启动NameServer和Broker，然后执行

  ```shell
  ./mqadmin updateTopic -n localhost:9876 -t stock -c DefaultCluster
  ```

  **缓存库存接入异步化**（代码层面实现异步消息队列发送的操作）

  **application.properties**

  ```properties
  mq.nameserver.addr={一个ip地址}:9876
  mq.topicname=stock
  ```

  **MqProducer.java**

  ```java
  @Component
  public class MqProducer {
    private DefaultMQProducer producer;
    private TransactionMQProducer transactionMQProducer;
    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    @Value("${mq.topicname}")
    private String topicName;
    @Autowired
    private OrderService orderService;
    @Autowired
    private StockLogDOMapper stockLogDOMapper;
    @PostConstruct(在Bean的初始化之后被调用)
    public void init() throws MQClientException {
      //做MQ Producer的初始化
      producer = new DefaultMQProducer("producer_group");
      producer.setNamesrvAddr(nameAddr);
      producer.start();
  
      transactionMQProducer = new TransactionMQProducer("transaction_producer_group");
      transactionMQProducer.setNamesrvAddr(nameAddr);
      transactionMQProducer.start();
  
      transactionMQProducer.setTransactionListener(new TransactionListener() {
        @Override
        public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
          //真正要做的事  创建订单
          Integer itemId = (Integer) ((Map) arg).get("itemId");
          Integer promoId = (Integer) ((Map) arg).get("promoId");
          Integer userId = (Integer) ((Map) arg).get("userId");
          Integer amount = (Integer) ((Map) arg).get("amount");
          String stockLogId = (String) ((Map) arg).get("stockLogId");
          try {
            orderService.createOrder(userId, itemId, promoId, amount, stockLogId);
          } catch (BusinessException e) {
            e.printStackTrace();
            //设置对应的stockLog为回滚状态
            StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
            stockLogDO.setStatus(3);
            stockLogDOMapper.updateByPrimaryKeySelective(stockLogDO);
            return LocalTransactionState.ROLLBACK_MESSAGE;
          }
          return LocalTransactionState.COMMIT_MESSAGE;
        }
  
        @Override
        public LocalTransactionState checkLocalTransaction(MessageExt msg) {
          //根据是否扣减库存成功，来判断要返回COMMIT,ROLLBACK还是继续UNKNOWN
          String jsonString = new String(msg.getBody());
          Map<String, Object> map = JSON.parseObject(jsonString, Map.class);
          Integer itemId = (Integer) map.get("itemId");
          Integer amount = (Integer) map.get("amount");
          String stockLogId = (String) map.get("stockLogId");
          StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
          if (stockLogDO == null) {
            return LocalTransactionState.UNKNOW;
          }
          if (stockLogDO.getStatus().intValue() == 2) {
            return LocalTransactionState.COMMIT_MESSAGE;
          } else if (stockLogDO.getStatus().intValue() == 1) {
            return LocalTransactionState.UNKNOW;
          }
          return LocalTransactionState.ROLLBACK_MESSAGE;
        }
      });
    }
  
    //事务型同步库存扣减消息
    public boolean transactionAsyncReduceStock(Integer userId, Integer itemId, Integer promoId, Integer amount, String stockLogId) {
      Map<String, Object> bodyMap = new HashMap<>();
      bodyMap.put("itemId", itemId);
      bodyMap.put("amount", amount);
      bodyMap.put("stockLogId", stockLogId);
  
      Map<String, Object> argsMap = new HashMap<>();
      argsMap.put("itemId", itemId);
      argsMap.put("amount", amount);
      argsMap.put("userId", userId);
      argsMap.put("promoId", promoId);
      argsMap.put("stockLogId", stockLogId);
  
      Message message = new Message(topicName, "increase",
          JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
      TransactionSendResult sendResult = null;
      try {
  
        sendResult = transactionMQProducer.sendMessageInTransaction(message, argsMap);
      } catch (MQClientException e) {
        e.printStackTrace();
        return false;
      }
      if (sendResult.getLocalTransactionState() == LocalTransactionState.ROLLBACK_MESSAGE) {
        return false;
      } else if (sendResult.getLocalTransactionState() == LocalTransactionState.COMMIT_MESSAGE) {
        return true;
      } else {
        return false;
      }
  
    }
  
    //同步库存扣减消息
    public boolean asyncReduceStock(Integer itemId, Integer amount) {
      Map<String, Object> bodyMap = new HashMap<>();
      bodyMap.put("itemId", itemId);
      bodyMap.put("amount", amount);
  
      Message message = new Message(topicName, "increase",
          JSON.toJSON(bodyMap).toString().getBytes(Charset.forName("UTF-8")));
      try {
        producer.send(message);
      } catch (MQClientException e) {
        e.printStackTrace();
        return false;
      } catch (RemotingException e) {
        e.printStackTrace();
        return false;
      } catch (MQBrokerException e) {
        e.printStackTrace();
        return false;
      } catch (InterruptedException e) {
        e.printStackTrace();
        return false;
      }
      return true;
    }
  }
  ```

  **MqConsumer.java**

  ```java
  @Component
  public class MqConsumer {
    private DefaultMQPushConsumer consumer;
    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    @Value("${mq.topicname}")
    private String topicName;
    @Autowired
    private ItemStockDOMapper itemStockDOMapper;
    @PostConstruct
    public void init() throws MQClientException {
      consumer = new DefaultMQPushConsumer("stock_consumer_group");
      consumer.setNamesrvAddr(nameAddr);
      //consumer监听哪一个topic的消息,"*":所有的消息
      consumer.subscribe(topicName, "*");
      //当消息推送过来之后，怎么处理
      consumer.registerMessageListener(new MessageListenerConcurrently() {
        @Override
        public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
          //实现库存从Redis真正到MySQL数据库内扣减的逻辑
          Message msg = msgs.get(0);
          String jsonString = new String(msg.getBody());
          Map<String, Object> map = JSON.parseObject(jsonString, Map.class);
          Integer itemId = (Integer) map.get("itemId");
          Integer amount = (Integer) map.get("amount");
          itemStockDOMapper.decreaseStock(itemId, amount);
          return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
        }
      });
      consumer.start();
    }
  }
  ```

  完成数据库中间键的接入后，我们应该怎样去用？

  **OrderService.java**

  ```java
  @Autowired
  private MqProducer mqProducer
  //同步库存扣减消息
  public boolean asyncReduceStock(Integer itemId, Integer amount){
    Map<String, Object> bodyMap = new HashMap<>();
    bodyMap.put("itemId",itemId);
    bodyMap.put("amount", amount);
    Message message = new Message(topicName,"increase",
    	JSON.toJSON(bodyMap).toStrin().getBytes(Charset.forName("UTF-8")));
    try {
  	  producer.send(message);  
    }catch{
      return false;
    }
    return true;
  }
  ```

  若信息发送成功（库存更新成功），在**ItemService**中：

  ```java
  decreaseStock(Integer itemId, Integer amount) .. 的方法中
  long result = redisTemplate.opsForValue().increment('promo_item_stock_'+itemId,amount.intValue() * -1);
  if(result >= 0){
  	boolean mqResult = mqProducer.asyncReduceStock(itemId,amount);
    if(!mqResult) {
      //更新库存失败
      redisTemplate.opsForValue().increment('promo_item_stock_'+itemId,amount.intValue() * +1);
      return false;
    }
    //更新库存成功
    return true;
  }else{
    //更新库存失败
    redisTemplate.opsForValue().increment('promo_item_stock_'+itemId,amount.intValue() * +1);
    return false;
  }
  ```

  潜在问题：

  1. 异步消息发送失败
  2. 扣减操作执行失败
  3. 下单失败无法正确回补库存



## 七. 交易性能优化技术之事务型消息

目标：

* 掌握异步化事务型消息模型
* 掌握库存售罄模型

**⚠️事务型消息**

在ItemService中，增加

```java
//异步更新库存
boolean asyncDecreaseStock(Integer itemId,Integer amount){
  boolean mqResult = mqProducer.asyncReduceStock(itemId,amount);
}
//库存回滚
boolean increaseStock(Integer itemId,Integer amount){
  redisTemplate.opsForValue().increment("promo_item_stock_"+itemId,amount.intValue());
  return true;
}
```

然后OrderService中：

```java
boolean mqResult = itemService.asyncDecreaseStock(itemId,amount);
if(!mqResult){
  itemService.increaseStoc(itemId,amount);
  throw new BussinessException(EmBusinessError.MQ_SEND_FAIL);
}
```

实现基于rocketMq的Transaction事务：

见上面的**MyProducer.java**代码（**事务型同步库存扣减消息**）

接下来的我跟不上了，看视频，从第七章开始



